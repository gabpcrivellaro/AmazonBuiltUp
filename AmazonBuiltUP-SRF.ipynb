{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports ok!\n",
      "ROI e datas ok!\n",
      "Funções ok!\n",
      "Total de poligonos de áreas iluminadas:  7273\n",
      "Total de poligonos de áreas iluminadas em sedes municipais de interesse:  6\n",
      "1 - Itaituba\n",
      "2 - Novo Progresso\n",
      "3 - Santarém\n",
      "4 - Altamira\n",
      "5 - São Felix do Xingú\n",
      "6 - Cametá\n",
      "\n",
      "AOI pronto!\n",
      "Número de níveis de cinza:  16\n",
      "Tmanho da janela:  3X3\n",
      "Número de árvores:  1000\n",
      "Itaituba  Iniciado!\n",
      "Itaituba : Mapa temático exportado!\n",
      "Novo Progresso  Iniciado!\n",
      "Novo Progresso : Mapa temático exportado!\n",
      "Santarém  Iniciado!\n",
      "Santarém : Mapa temático exportado!\n",
      "Altamira  Iniciado!\n",
      "Altamira : Mapa temático exportado!\n",
      "São Felix do Xingú  Iniciado!\n",
      "São Felix do Xingú : Mapa temático exportado!\n",
      "Cametá  Iniciado!\n",
      "Cametá : Mapa temático exportado!\n",
      "Pronto!\n"
     ]
    }
   ],
   "source": [
    "#######################################################################################################################\n",
    "#                                   AmazonBuiltUP - Single Random Forest - SRF                                        #\n",
    "#######################################################################################################################\n",
    "#Algoritmo desenvolvido para mapear áreas construídas em sedes municipais de cidades amazônicas                       #\n",
    "#Esse script foi criado para classificar imaagens Sentinel-2, também são utilizados dados do VIIRS,                   #\n",
    "#pontos de sedes municipais (IBGE) e amostras de treinamento                                                          #\n",
    "#O mapa temático final possui 5 classes: Solo Exposto; Área Construída, Água, Vegetação Arbórea e Vegetação Herbácea  #\n",
    "#Autor: Gabriel Crivellaro Gonçalves                                                                                  #\n",
    "#######################################################################################################################\n",
    "\n",
    "#Importar as bibliotecas\n",
    "import ee\n",
    "ee.Initialize()\n",
    "#Mostra uma mensagem informando que as bibliotecas foram importadas com sucesso\n",
    "print('Imports ok!')\n",
    "#Cria uma geometria do estado do pará a ser utilizada para adiquirir as imagens VIIRS\n",
    "shp_f = ee.FeatureCollection(\"users/gabrielcrivellarog/PA\")\n",
    "geometry=shp_f.geometry().bounds()\n",
    "#Cria uma geometria de pontos das sedes municipais escolhidas\n",
    "sedes_fc = ee.FeatureCollection('users/gabrielcrivellarog/sedes_mun_estudo')\n",
    "sedes = sedes_fc.geometry()\n",
    "#Define o intervalo de datas para aquisição das imagens sentinel-2\n",
    "START_DATE = ee.Date('2020-01-01')\n",
    "END_DATE = ee.Date('2020-12-31')\n",
    "#Define o intervalo de datas para aquisição dos dados VIIRS\n",
    "d1 = '2020-05-01'\n",
    "d2 = '2020-10-31'\n",
    "#Carrega a coleção da imagens do Sentinel-2 SR\n",
    "s2Sr_col = ee.ImageCollection('COPERNICUS/S2_SR')\n",
    "#Carrega a coleção de mascaras de núvens do Sentinel-2\n",
    "s2Clouds = ee.ImageCollection('COPERNICUS/S2_CLOUD_PROBABILITY')\n",
    "#Carrega a coleção da imagens VIIRS par o estado do PA e para as datas definidas\n",
    "col_viirs=ee.ImageCollection('NOAA/VIIRS/DNB/MONTHLY_V1/VCMCFG').filterBounds(geometry).filterDate(d1,d2) \n",
    "#Mostra uma mensagem informado que a região de intersse foi criada e definidas as datas\n",
    "print('ROI e datas ok!')\n",
    "#Cria Função para o calculo do GLCM\n",
    "#quant_levels = número de níveis de cinza a ser requantizado\n",
    "#scale = tamanho do pixel (m)\n",
    "#size = tamanho da janela kernel (1 = 3x3; 2 = 5x5)\n",
    "def compute_probabilistic_glcm(img,quant_levels,scale,size,geom):\n",
    "    qt_img = probabilistic_quantizer(img,quant_levels,scale,geom).rename(['glcm'])\n",
    "    return qt_img.glcmTexture(size)\n",
    "#Cria Função para para requantizar a imagem pelo metodo de probabilidades iguais\n",
    "def probabilistic_quantizer(img,num_levels,scale,geom):\n",
    "    img = ee.Image(img)\n",
    "    num_levels = ee.Number(num_levels)\n",
    "    region = ee.Geometry(geom)\n",
    "    percentiles = ee.List.sequence(0,num_levels).map(lambda i: ee.Number(i).multiply(100).divide(num_levels))\n",
    "    reducer = ee.Reducer.percentile(percentiles)\n",
    "    quantis = img.reduceRegion(reducer = reducer, geometry = region, scale = scale, maxPixels = 25000000000000000, bestEffort = True)\n",
    "    quantis_values = quantis.values(quantis.keys()).sort()\n",
    "\n",
    "    def get_fraction(pair):\n",
    "        pair = ee.List(pair)\n",
    "        low_bound  = ee.Number(pair.get(0))\n",
    "        high_bound = ee.Number(pair.get(1))\n",
    "        return ee.Image(1).updateMask(img.gt(low_bound).And(img.lt(high_bound)))\n",
    "\n",
    "    img_req_col = ee.ImageCollection(quantis_values.zip(quantis_values.slice(1)).map(get_fraction))\n",
    "\n",
    "    l=ee.List.sequence(0,num_levels.subtract(1))\n",
    "    img_req_col_list = img_req_col.toList(num_levels)\n",
    "\n",
    "    def create_quantized_col(i):\n",
    "        i = ee.Number(i)\n",
    "        return ee.Image(img_req_col_list.get(i)).multiply(ee.Number(i).add(1)).toByte()\n",
    "\n",
    "    mul_col = ee.ImageCollection(l.map(create_quantized_col))\n",
    "\n",
    "    return mul_col.mosaic()\n",
    "def spectral_glcm_band_name(glcm_image,spectral_band):\n",
    "    bandname = spectral_band.bandNames().getInfo()\n",
    "    bandname = str(bandname[0])\n",
    "    new_glcm_band_names = []\n",
    "    glcm_bands_names = glcm_image.bandNames().remove(\"glcm_maxcorr\").getInfo()\n",
    "    for i in glcm_bands_names:\n",
    "        band_name_glcm = bandname+'_'+i\n",
    "        new_glcm_band_names.append(band_name_glcm)\n",
    "    glcm_image_N = glcm_image.select(glcm_bands_names).rename(new_glcm_band_names)\n",
    "    return glcm_image_N\n",
    "#Cria Função que adiociona um campo (sede) no vetor poligonos de áreas iluminadas (VIIRS) \n",
    "# e atribui 1 para os poligonos que intersectam os pontos das sedes municipais e 0 que não intersectam.\n",
    "def cruzaSede(ft):\n",
    "    return ft.set('sede',ft.intersects(sedes))\n",
    "#Cria Função para constuir mosaico de imagens Sentinel-2 livre de núvens (RICHTER, 2017)\n",
    "def maskClouds(img):\n",
    "    clouds = ee.Image(img.get('cloud_mask')).select('probability')\n",
    "    isNotCloud = clouds.lt(MAX_CLOUD_PROBABILITY)\n",
    "    return img.updateMask(isNotCloud)\n",
    "#Cria Função para corrigir defeitos de bordas das cenas (RICHTER, 2017)\n",
    "def maskEdges(s2_img):\n",
    "    return s2_img.updateMask(s2_img.select('B8A').mask().updateMask(s2_img.select('B9').mask()))\n",
    "#Mostra uma mensagem informando que as funções foram criadas\n",
    "print('Funções ok!')\n",
    "#Calcula a média das composições mensais do VIIRS dentre o período definido\n",
    "nighttime=col_viirs.mean().clip(geometry).select('avg_rad')\n",
    "#Cria uma imagem bináriacom valor de 1 para os pixels com valor maior que 1 e 0 para os pixels com valore menor que 1\n",
    "zones = nighttime.gt(0.8)\n",
    "#Vetoriza a imagem binária do viirs\n",
    "vectors = zones.addBands(nighttime).reduceToVectors(geometry = geometry,\n",
    "                                                     crs=\"EPSG:31981\",\n",
    "                                                     scale = 500,\n",
    "                                                     geometryType = 'polygon',\n",
    "                                                     eightConnected = True,\n",
    "                                                     labelProperty = 'zone',\n",
    "                                                     reducer = ee.Reducer.mean(),\n",
    "                                                    maxPixels=15718696000000000 )\n",
    "#Utiliza a função cruzaSede identificar os poligonos de áreas iluminadas que intersectam as sedes municipais de interesse\n",
    "vectors = vectors.map(cruzaSede)\n",
    "#cria um vetor apenas com os poligonos que possuem valor 1 (True) no campo \"sede\"\n",
    "vectors_sedes =vectors.filterMetadata('sede','equals',True)\n",
    "#Cria uma lista com o ID de cada um dos poligonos do vetor vectors_sedes\n",
    "sede_id = vectors_sedes.aggregate_array('system:index').getInfo()\n",
    "#Cria um filtro para identificar a intersecção entre duas geometrias\n",
    "filter = ee.Filter.intersects(leftField='.geo',rightField='.geo')\n",
    "#Define uma operação para unir duas camadas vetoriais (sedes e poligonos iluminados) e cria um campo com a palavra 'SEDE'\n",
    "join = ee.Join.saveFirst(matchKey = 'SEDE')\n",
    "#Cria uma nova camada vetorial dos poligonos iluminados em sedes municipais \n",
    "#com os campos de informações do vetor de pontos de sedes municipais (Nome das sedes e sigla das sedes)\n",
    "vectors_joined = join.apply(vectors_sedes, sedes_fc,filter)\n",
    "#Cria uma lista vazia para armazenar os nomes dos municipios das sedes analisadas\n",
    "mun_nomes_interesse = []\n",
    "#Cria uma variável de contagem para exibir uma contagem\n",
    "c=1\n",
    "#Cria uma geometria das áreas iluminadas nas sedes de estudo\n",
    "AOI1 = vectors_sedes.geometry() \n",
    "#Conta o número de poligonos de áreas iluminadas que intersectaram as sedes que não intersectaram\n",
    "cruza_sede_result = vectors.aggregate_histogram('sede').getInfo()\n",
    "#Mostra o total de poligonos de áreas iluminadas que não intersectaram as sedes\n",
    "print('Total de poligonos de áreas iluminadas: ',cruza_sede_result['false'])\n",
    "#Mostra o total de poligonos de áreas iluminadas que intersectaram as sedes\n",
    "print('Total de poligonos de áreas iluminadas em sedes municipais de interesse: ',cruza_sede_result['true'])\n",
    "#Define um laço para mostrar o nome dos municipios em que os poligonos iluminados intersectaram as sedes\n",
    "for i in sede_id:\n",
    "    #Interendo entre os IDs dos poligonos iluminados em sedes\n",
    "    #cria uma nova camada vetorial com o poligono que possue mesmo ID (index) \n",
    "    get_name = vectors_joined.filterMetadata('system:index','equals',i)\n",
    "    #Cria uma variável string com o nome do municipio ao qual o poligono de área iluminada intersecta a sede\n",
    "    Sede_nome = ee.Feature(get_name.first().get('SEDE')).get('NAME').getInfo()\n",
    "    #adiciona o nome do municipio a lista com o nome dos muncipios das sedes\n",
    "    mun_nomes_interesse.append(Sede_nome)\n",
    "    #Mostra o nome do municipio com um número de contagem\n",
    "    print(c,'-',Sede_nome)\n",
    "    #Adiciona 1 ao valor de c para o contador\n",
    "    c=c+1\n",
    "#Mostra uma linha vazia para separar as informações\n",
    "print()\n",
    "#Mostra uma mensagem informando que a AOI1 foi criada com sucesso\n",
    "print('AOI pronto!')\n",
    "#Filtra as imagens da coleção Sentinel-2 que intersectam a AOI1 e atendem ao intevalo de datas definido \n",
    "criteria = s2Sr_col.filterBounds(AOI1).filterDate(START_DATE,END_DATE)\n",
    "#Aplica a função maskEdges na imagem\n",
    "s2Sr = criteria.map(maskEdges)\n",
    "#Filtra as bandas de probilidade de núvens para a area de intersse e datas definidas\n",
    "s2Clouds = s2Clouds.filterBounds(AOI1).filterDate(START_DATE,END_DATE)\n",
    "#Junta as imagens Sentinel-2 com a imagem de probabilidade de núvens\n",
    "s2SrWithCloudMask = ee.Join.saveFirst('cloud_mask').apply(primary= criteria,\n",
    "                                                           secondary= s2Clouds,\n",
    "                                                           condition=ee.Filter.equals(leftField = 'system:index', rightField = 'system:index'))\n",
    "#Define a proprabilidade máxima de presença de núvens\n",
    "MAX_CLOUD_PROBABILITY = 30\n",
    "#Seleciona todos os pixels de todas imagens que possuem até 30% de probabilidade de núvens\n",
    "#E cria um mosaico a partir do valor médio de cada pixel em cada imagem\n",
    "s2CloudMasked = ee.ImageCollection(s2SrWithCloudMask).map(maskClouds).median()\n",
    "#Seleciona as bandas espectrais de 10m a serem utilizadas \n",
    "s2CloudMasked = s2CloudMasked.clip(AOI1).select('B4','B3','B2','B8')\n",
    "#Calcula o NDVI\n",
    "ndvi = ee.Image(s2CloudMasked.normalizedDifference(['B8', 'B4'])).rename('NDVI')\n",
    "#Calcula o NDWI\n",
    "ndwi = ee.Image(s2CloudMasked.normalizedDifference(['B3', 'B8'])).rename('NDWI')\n",
    "\n",
    "#Cria uma banda espectral para cada banda utilizada\n",
    "B_RED = s2CloudMasked.select('B4').rename('R')\n",
    "B_GREEN = s2CloudMasked.select('B3').rename('G')\n",
    "B_BLUE = s2CloudMasked.select('B2').rename('B')\n",
    "B_NIR = s2CloudMasked.select('B8').rename('N')\n",
    "\n",
    "#Número de níveis de cinza\n",
    "dig_levels = 16\n",
    "#Tamanho da janela kernel\n",
    "kernel = 1\n",
    "#Número de árvores de decisão \n",
    "trees = 1000\n",
    "#Mostra o número de níveis de cinza escolhido\n",
    "print(\"Número de níveis de cinza: \",dig_levels)\n",
    "#Mostra o tamanho da janela kernel\n",
    "if kernel==1:\n",
    "    w='3X3'\n",
    "    print(\"Tmanho da janela: \",w)\n",
    "else:\n",
    "    w='5X5'\n",
    "    print(\"Tmanho da janela: \",w)\n",
    "#Mostra o número de árvores de decisão\n",
    "print(\"Número de árvores: \",trees)\n",
    "#cria uma string com todos os hiperparametros escolhidos para identificar os arquivos de saída\n",
    "s = 'SRF_T'+str(trees)+'_W'+str(w)+'_DL'+str(dig_levels)\n",
    "\n",
    "#Utiliza a função compute_probabilistic_glcm para requantizar as bandas e gera a matrix GLCM e calcula as métricas\n",
    "RED_GLCM = compute_probabilistic_glcm(B_RED.clip(AOI1.bounds()),dig_levels,10,kernel,AOI1)\n",
    "RED_GLCM = spectral_glcm_band_name(RED_GLCM,B_RED)\n",
    "GREEN_GLCM = compute_probabilistic_glcm(B_GREEN.clip(AOI1.bounds()),dig_levels,10,kernel,AOI1)\n",
    "GREEN_GLCM = spectral_glcm_band_name(GREEN_GLCM,B_GREEN)\n",
    "BLUE_GLCM = compute_probabilistic_glcm(B_BLUE.clip(AOI1.bounds()),dig_levels,10,kernel,AOI1)\n",
    "BLUE_GLCM = spectral_glcm_band_name(BLUE_GLCM,B_BLUE)\n",
    "NIR_GLCM = compute_probabilistic_glcm(B_NIR.clip(AOI1.bounds()),dig_levels,10,kernel,AOI1)\n",
    "NIR_GLCM = spectral_glcm_band_name(NIR_GLCM,B_NIR)\n",
    "print('Dados de entrada prontos, classificação iniciada!')\n",
    "#Cria uma imagem com as 4 bandas espectrais, 18 métricas de textura para cada banda espectral, NDVI e NDWI\n",
    "image_class = RED_GLCM.addBands(GREEN_GLCM).addBands(BLUE_GLCM).addBands(NIR_GLCM).addBands(B_RED).addBands(B_GREEN).addBands(B_BLUE).addBands(B_NIR).addBands(ndvi).addBands(ndwi)\n",
    "#carregar as amostras\n",
    "sample = ee.FeatureCollection(\"users/gabrielcrivellarog/amostra_2020_ALL\")\n",
    "#Cria uma coluna com valores aleatórios entre 0 e 1 para cada polígono\n",
    "sample = sample.randomColumn(seed=1)\n",
    "#Definir o percentual a ser utilziado para teste e treinamento\n",
    "split = 0.6\n",
    "#Cria uma camada vetorial com as amostras de treinamento\n",
    "training = sample.filter(ee.Filter.lt('random', split))\n",
    "#Cria uma camada vetorial com as amostras de teste\n",
    "validation = sample\n",
    "\n",
    "#Extrai todas as informações de todas bandas de todos os pixels que intersectam os poligonos\n",
    "training_values = image_class.sampleRegions(collection= training,properties= ['C_ID'],scale= 10,geometries=True)\n",
    "#Remove as amostras que podem ter ficado em área sem informação\n",
    "trainingNoNulls = training_values.filter(ee.Filter.notNull(training_values.first().propertyNames()))\n",
    "#Exporta para o GoogleDrive uma planillha com os valores amostrados para cada pixel\n",
    "N_TD= s+'_treino' \n",
    "task=ee.batch.Export.table.toDrive(collection = trainingNoNulls,description = N_TD, folder = 'AmazonBuiltUp_SRF')\n",
    "task.start()\n",
    "\n",
    "#Cria um classificador random forest e treina com as amostras coletadas.\n",
    "classifier = ee.Classifier.smileRandomForest(numberOfTrees=trees,bagFraction=1,seed=1).train(features= trainingNoNulls,classProperty='C_ID')\n",
    "#Classifica a imagem com o Rabdom Forest\n",
    "classified = image_class.classify(classifier)\n",
    "#Conta o numero de amostras utilizadas no treinamento\n",
    "#labels = trainingNoNulls.aggregate_histogram('C_ID').getInfo()\n",
    "#print ('Labels:',labels)\n",
    "\n",
    "for i in sede_id:\n",
    "    \n",
    "    AOI_sede = vectors_sedes.filterMetadata('system:index','equals',i).geometry()\n",
    "    get_name = vectors_joined.filterMetadata('system:index','equals',i)\n",
    "    Sede_nome = ee.Feature(get_name.first().get('SEDE')).get('NAME').getInfo()\n",
    "    Sede_nome_sigla = ee.Feature(get_name.first().get('SEDE')).get('SIGLA').getInfo()\n",
    "    cidade_name = Sede_nome_sigla\n",
    "    print (Sede_nome, ' Iniciado!')\n",
    "\n",
    "    #Concateda a sigla do municipio com a identificação da imagem de saída\n",
    "    name = cidade_name + '_' + s +'_CLASS_20'\n",
    "    #Exporta para o GoogleDrive o mapa temático final\n",
    "    task_im = ee.batch.Export.image.toDrive(image = classified.clip(AOI_sede), description=name, folder='AmazonBuiltUp_SRF', region=AOI_sede, scale=10, crs = 'EPSG:31981')\n",
    "    task_im.start()\n",
    "\n",
    "   \n",
    "    print(Sede_nome, ': Mapa temático exportado!')\n",
    "\n",
    "#Cria um dicionário com os resultados do RF\n",
    "dict_ = classifier.explain()\n",
    "\n",
    "#Exporta os resultados do classificador em uma tabela no GDrive\n",
    "explain = ee.FeatureCollection(ee.Feature(None, ee.Dictionary(dict_)))\n",
    "N_explain = s+'_explain' \n",
    "task_explain=ee.batch.Export.table.toDrive(collection = explain, description = N_explain, folder = 'AmazonBuiltUp_SRF') \n",
    "task_explain.start() \n",
    "\n",
    "#Exporta os a importancia das variáveis do classificador em uma tabela no GDrive\n",
    "variable_importance = ee.FeatureCollection(ee.Feature(None, ee.Dictionary(dict_).get('importance')))\n",
    "N_ID = s+'_importance' \n",
    "task_i=ee.batch.Export.table.toDrive(collection = variable_importance, description = N_ID, folder = 'AmazonBuiltUp_SRF') \n",
    "task_i.start()\n",
    "\n",
    "#Calcula a matrix de confusão de treino\n",
    "CM = classifier.confusionMatrix()\n",
    "#EConverte a matrix de confusão de treino em uma feature (tabela)\n",
    "train_accuracy = ee.Feature(None,{'matrix':CM.array()})\n",
    "#Exporta a matriz de confusão de treino em uma tabela no Gdrive\n",
    "N_AT = s + '_Acuracia_treino' \n",
    "task_it=ee.batch.Export.table.toDrive(collection = ee.FeatureCollection(train_accuracy), description = N_AT, folder = 'AmazonBuiltUp_SRF') \n",
    "task_it.start()\n",
    "\n",
    "#Identifica a classe predita no mapa temático final das amostras de validação separadas e exclui as amostras em null\n",
    "validated_values = classified.sampleRegions(collection= validation,properties= ['C_ID'],scale= 10,geometries=True)\n",
    "validated_valuesNoNulls = validated_values.filter(ee.Filter.notNull(validated_values.first().propertyNames()))\n",
    "#Exporta os pontos amostrados em .shp no Gdrive\n",
    "N_TDP= s + '_teste' \n",
    "taskTP=ee.batch.Export.table.toDrive(collection = validated_valuesNoNulls,description = N_TDP, folder = 'AmazonBuiltUp_SRF',fileFormat=\"SHP\")\n",
    "taskTP.start() \n",
    "#Calcula a matriz de erro\n",
    "test_accuracy = validated_valuesNoNulls.errorMatrix('C_ID', 'classification',[1,2,3,4,5])\n",
    "#Transforma a matriz de erro em uma feature (tabela)\n",
    "test_accuracy_fe = ee.Feature(None,{'matrix':(test_accuracy).array()})\n",
    "#Exporta a matriz de erro em uma tabela no Gdrive\n",
    "N_TA = s + '_Acuracia_teste' \n",
    "task_ta=ee.batch.Export.table.toDrive(collection = ee.FeatureCollection(test_accuracy_fe), description = N_TA, folder = 'AmazonBuiltUp_SRF') \n",
    "task_ta.start()\n",
    "print('Avaliação de Acurácia iniciada!')\n",
    "#Mostra a matriz de erro e calcula e mostra a acurácia global, acurácia do consumidor, acurácia do produtor e o coeficiente de kappa\n",
    "print('Matrix de erro da validação: ', test_accuracy.getInfo())\n",
    "print('Acurácia global da validação: ', test_accuracy.accuracy().getInfo())\n",
    "print('Matrix do consumidor da validação: ', test_accuracy.consumersAccuracy().getInfo())\n",
    "print('Acurácia do produtor da validação: ', test_accuracy.producersAccuracy().getInfo())\n",
    "print('kappa da validação: ', test_accuracy.kappa().getInfo())\n",
    "#Mostra que a classificação foi conclúida e mostra o valor das do pixel de cada classe\n",
    "print('Processamento concluído! - Solo Exposto: 1; Área Construída: 2; Água: 3; Herbácea: 4; Arbórea: 5.')\n",
    "print('Fim!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
